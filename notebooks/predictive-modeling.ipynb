{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb5a4a9e",
   "metadata": {},
   "source": [
    "# Titanic - Predictive Modeling!\n",
    "In our last session, we focused on performing feature engineering on the raw Titanic dataset. At the end of that session, we exported our cleaned dataset into another CSV file. We are now ready to start our predictive modeling process!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a0a1f5",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d9236d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary Python libraries\n",
    "import cloudpickle\n",
    "import pandas as pd\n",
    "from category_encoders.one_hot import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3ac1004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the cleaned datasets\n",
    "X = pd.read_csv('../data/clean/X.csv')\n",
    "y = pd.read_csv('../data/clean/y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2408bab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_nan</th>\n",
       "      <th>Age_child</th>\n",
       "      <th>Age_teen</th>\n",
       "      <th>Age_young_adult</th>\n",
       "      <th>Age_adult</th>\n",
       "      <th>Age_elder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  SibSp  Parch     Fare  Sex_male  Sex_female  Embarked_S  \\\n",
       "0       3      1      0   7.2500         1           0           1   \n",
       "1       1      1      0  71.2833         0           1           0   \n",
       "2       3      0      0   7.9250         0           1           1   \n",
       "3       1      1      0  53.1000         0           1           1   \n",
       "4       3      0      0   8.0500         1           0           1   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Embarked_nan  Age_child  Age_teen  Age_young_adult  \\\n",
       "0           0           0             0          0         0                1   \n",
       "1           1           0             0          0         0                0   \n",
       "2           0           0             0          0         0                1   \n",
       "3           0           0             0          0         0                0   \n",
       "4           0           0             0          0         0                0   \n",
       "\n",
       "   Age_adult  Age_elder  \n",
       "0          0          0  \n",
       "1          1          0  \n",
       "2          0          0  \n",
       "3          1          0  \n",
       "4          1          0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the first few rows of the X dataset\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bf99aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived\n",
       "0         0\n",
       "1         1\n",
       "2         1\n",
       "3         1\n",
       "4         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the first few rows of the y dataset\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81eff3e1",
   "metadata": {},
   "source": [
    "## Data Separation\n",
    "When working with a training dataset, it is a good idea to hold out a portion of the data so that we have something we can validate the model against. In the cell below, we will use Scikit-Learn's `train_test_split` functionality to split the data into respective training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2206a841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the datasets between training and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea94e55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_nan</th>\n",
       "      <th>Age_child</th>\n",
       "      <th>Age_teen</th>\n",
       "      <th>Age_young_adult</th>\n",
       "      <th>Age_adult</th>\n",
       "      <th>Age_elder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  SibSp  Parch     Fare  Sex_male  Sex_female  Embarked_S  \\\n",
       "331       1      0      0  28.5000         1           0           1   \n",
       "733       2      0      0  13.0000         1           0           1   \n",
       "382       3      0      0   7.9250         1           0           1   \n",
       "704       3      1      0   7.8542         1           0           1   \n",
       "813       3      4      2  31.2750         0           1           1   \n",
       "\n",
       "     Embarked_C  Embarked_Q  Embarked_nan  Age_child  Age_teen  \\\n",
       "331           0           0             0          0         0   \n",
       "733           0           0             0          0         0   \n",
       "382           0           0             0          0         0   \n",
       "704           0           0             0          0         0   \n",
       "813           0           0             0          1         0   \n",
       "\n",
       "     Age_young_adult  Age_adult  Age_elder  \n",
       "331                0          1          0  \n",
       "733                1          0          0  \n",
       "382                0          1          0  \n",
       "704                1          0          0  \n",
       "813                0          0          0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the first few rows of the X_train dataset\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2867eb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived\n",
       "331         0\n",
       "733         0\n",
       "382         0\n",
       "704         0\n",
       "813         0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the first few rows of the y_train dataset\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce271615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20089786756453423"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking to see that the 20% split worked properly\n",
    "len(X_val) / len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3abf83",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8179b8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating a Random Forest Classifier object\n",
    "rfc_gridsearch = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "487099e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the parameter grid for hyperparameter tuning\n",
    "params = {'n_estimators': [10, 50, 100],\n",
    "          'min_samples_split': [2, 5, 10],\n",
    "          'min_samples_leaf': [1, 2, 5],\n",
    "          'max_depth': [10, 20, 50]\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ba8bc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the GridSearchCV object\n",
    "hyperparameter_tuner = GridSearchCV(estimator = rfc_gridsearch,\n",
    "                                    param_grid = params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76f0ba0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [10, 20, 50],\n",
       "                         'min_samples_leaf': [1, 2, 5],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [10, 50, 100]})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running the hyperparameter tuning job\n",
    "hyperparameter_tuner.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "642b0e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 50,\n",
       " 'min_samples_leaf': 5,\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 10}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the best parameters from the hyperparameter tuning job\n",
    "hyperparameter_tuner.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c8fe86",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10f65d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating a new Random Forest Classifier object\n",
    "rfc_model = RandomForestClassifier(n_estimators = 50,\n",
    "                                   max_depth = 20,\n",
    "                                   min_samples_split = 10,\n",
    "                                   min_samples_leaf = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2289f30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=20, min_samples_leaf=2, min_samples_split=10,\n",
       "                       n_estimators=50)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing the model training\n",
    "rfc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b31d600",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1101ddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting predictions on the X_val dataset using the trained RFC model\n",
    "val_preds = rfc_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8893960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the metrics with the validation dataset\n",
    "val_accuracy = accuracy_score(y_val, val_preds)\n",
    "val_roc_auc = roc_auc_score(y_val, val_preds)\n",
    "val_confusion_matrix = confusion_matrix(y_val, val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74e688e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8268156424581006\n",
      "ROC-AUC Score: 0.8124839124839125\n",
      "Confusion Matrix: \n",
      "[[94 11]\n",
      " [20 54]]\n"
     ]
    }
   ],
   "source": [
    "# Printing out the validation metrics\n",
    "print(f'Accuracy Score: {val_accuracy}')\n",
    "print(f'ROC-AUC Score: {val_roc_auc}')\n",
    "print(f'Confusion Matrix: \\n{val_confusion_matrix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e557616",
   "metadata": {},
   "source": [
    "## Saving out a Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29d5629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the RFC model to a pickle\n",
    "with open('../models/rfc_model.pkl', 'wb') as f:\n",
    "    cloudpickle.dump(rfc_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ddb883",
   "metadata": {},
   "source": [
    "## Loading our Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2dedeb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the RFC model from serialized file\n",
    "with open('../models/rfc_model.pkl', 'rb') as f:\n",
    "    rfc_loaded_model = cloudpickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b797811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting predictions with the loaded model\n",
    "loaded_preds = rfc_loaded_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2bcd253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8268156424581006\n",
      "ROC-AUC Score: 0.8124839124839125\n",
      "Confusion Matrix: \n",
      "[[94 11]\n",
      " [20 54]]\n"
     ]
    }
   ],
   "source": [
    "# Showing the metrics with the loaded preds\n",
    "val_accuracy = accuracy_score(y_val, loaded_preds)\n",
    "val_roc_auc = roc_auc_score(y_val, loaded_preds)\n",
    "val_confusion_matrix = confusion_matrix(y_val, loaded_preds)\n",
    "\n",
    "print(f'Accuracy Score: {val_accuracy}')\n",
    "print(f'ROC-AUC Score: {val_roc_auc}')\n",
    "print(f'Confusion Matrix: \\n{val_confusion_matrix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2674afd",
   "metadata": {},
   "source": [
    "## Creating a Full Pipeline\n",
    "In our livestream on Sept. 9, we focused on training a model and just saving that model alone. It is possible to save a serialized pickle file that not only contains the ability to perform inference on cleaned data but can also do that data cleansing itself. In this section, we'll be taking everything we've done so far to create a full ML inference pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31d205d",
   "metadata": {},
   "source": [
    "### Loading Raw Data\n",
    "Since our pipeline is going to take data in pretty much it's purest, rawest form, we are going to load in that original raw dataset we downloaded from Kaggle instead of working with our already cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea1aca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the raw Titanic training data\n",
    "df_raw = pd.read_csv('../data/raw/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bdbf891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating predictor value from the remainder of the dataset\n",
    "X = df_raw.drop(columns = ['Survived'])\n",
    "y = df_raw[['Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2a39732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing training / validation dataset split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2cd112",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "As part of our feature engineering, you might recall that we did some special things to create certain features. Before we jump into creating our pipeline, we'll need to package that feature engineering as their own respective Python functions. You'll notice this code is pretty much copy/pasted as is from our feature engineering notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9c5b6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to appropriately engineer the 'Age' column\n",
    "def create_age_bins(df):\n",
    "    '''Engineers age bin variables for the pipeline'''\n",
    "    \n",
    "    # Filling any null values with the median age of 28.0\n",
    "    median_age = 28.0\n",
    "    df['Age'].fillna(median_age, inplace = True)\n",
    "    \n",
    "    # Establishing our bins values and names\n",
    "    bin_labels = ['child', 'teen', 'young_adult', 'adult', 'elder']\n",
    "    bin_values = [-1, 12, 19, 30, 60, 100]\n",
    "    \n",
    "    # Applying \"Age\" binning with Pandas cut\n",
    "    age_bins = pd.cut(df['Age'], bins = bin_values, labels = bin_labels)\n",
    "    df_age_bins = pd.DataFrame(age_bins)\n",
    "    \n",
    "    # Dropping the original \"Age\" column\n",
    "    df.drop(columns = ['Age'], inplace = True)\n",
    "    \n",
    "    # Concatenating the new \"Age\" column to the original DataFrame\n",
    "    df = pd.concat([df, df_age_bins], axis = 1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a7bcc3",
   "metadata": {},
   "source": [
    "### Pipeline Creation\n",
    "Now that we have created our helper functions to perform the feature engineering, we are ready to begin packaging everything as a single, unified pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36eb97bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the \"Age\" binning function transformer as the first step into our modeling pipeline\n",
    "age_binner = FunctionTransformer(create_age_bins, validate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b371910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the data preprocessor that will perform our feature engineering\n",
    "data_preprocessor = ColumnTransformer(transformers = [\n",
    "    ('ohe_engineering', OneHotEncoder(use_cat_names = True, handle_unknown = 'ignore'), ['Age', 'Sex', 'Embarked']),\n",
    "    ('columns_to_drop', 'drop', ['PassengerId', 'Name', 'Ticket', 'Cabin'])],\n",
    "                                      remainder = 'passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4c277d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the full inference pipeline\n",
    "rfc_pipeline = Pipeline(steps = [\n",
    "    ('age_binning', age_binner),\n",
    "    ('feature_engineering', data_preprocessor),\n",
    "    ('predictive_modeling', RandomForestClassifier(n_estimators = 50,\n",
    "                                                   max_depth = 20,\n",
    "                                                   min_samples_split = 10,\n",
    "                                                   min_samples_leaf = 2))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e983f411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('age_binning',\n",
       "                 FunctionTransformer(func=<function create_age_bins at 0x7f9db92c8ca0>)),\n",
       "                ('feature_engineering',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('ohe_engineering',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                use_cat_names=True),\n",
       "                                                  ['Age', 'Sex', 'Embarked']),\n",
       "                                                 ('columns_to_drop', 'drop',\n",
       "                                                  ['PassengerId', 'Name',\n",
       "                                                   'Ticket', 'Cabin'])])),\n",
       "                ('predictive_modeling',\n",
       "                 RandomForestClassifier(max_depth=20, min_samples_leaf=2,\n",
       "                                        min_samples_split=10,\n",
       "                                        n_estimators=50))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the inference pipeline with the training data\n",
    "rfc_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec0c390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating inferences on the validation dataset with the trained RFC pipeline\n",
    "val_preds = pd.DataFrame(rfc_pipeline.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "abe808dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the metrics with the validation dataset\n",
    "val_accuracy = accuracy_score(y_val, val_preds)\n",
    "val_roc_auc = roc_auc_score(y_val, val_preds)\n",
    "val_confusion_matrix = confusion_matrix(y_val, val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2872e0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8340807174887892\n",
      "ROC-AUC Score: 0.8166610766392757\n",
      "Confusion Matrix: \n",
      "[[121  13]\n",
      " [ 24  65]]\n"
     ]
    }
   ],
   "source": [
    "# Printing out the validation metrics\n",
    "print(f'Accuracy Score: {val_accuracy}')\n",
    "print(f'ROC-AUC Score: {val_roc_auc}')\n",
    "print(f'Confusion Matrix: \\n{val_confusion_matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e2d4296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the pipeline to a serialized pickle file\n",
    "with open('../models/rfc_pipeline.pkl', 'wb') as f:\n",
    "    cloudpickle.dump(rfc_pipeline, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3207d5",
   "metadata": {},
   "source": [
    "### Loading Our Trained Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bee3d967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the trained RFC pipeline from the serialized pickle file\n",
    "with open('../models/rfc_pipeline.pkl', 'rb') as f:\n",
    "    loaded_rfc_pipeline = cloudpickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4f5f5273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting inferences with the loaded RFC pipeline\n",
    "val_preds = pd.DataFrame(loaded_rfc_pipeline.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9c197d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8340807174887892\n",
      "ROC-AUC Score: 0.8166610766392757\n",
      "Confusion Matrix: \n",
      "[[121  13]\n",
      " [ 24  65]]\n"
     ]
    }
   ],
   "source": [
    "# Getting the metrics with the validation dataset\n",
    "val_accuracy = accuracy_score(y_val, val_preds)\n",
    "val_roc_auc = roc_auc_score(y_val, val_preds)\n",
    "val_confusion_matrix = confusion_matrix(y_val, val_preds)\n",
    "\n",
    "# Printing out the validation metrics\n",
    "print(f'Accuracy Score: {val_accuracy}')\n",
    "print(f'ROC-AUC Score: {val_roc_auc}')\n",
    "print(f'Confusion Matrix: \\n{val_confusion_matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9ddeb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
